{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concrete Crack Detection with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Installation and Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download the data**\n",
    "\n",
    "In case you can't find it on the internet. I will provide a code here, which can be runned to install the dataset automatically into your local file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About the Data**\n",
    "- The dataset contains concrete images having cracks. The data is collected from various METU Campus Buildings.\n",
    "- The dataset is divided into two as negative and positive crack images for image classification. \n",
    "- Each class has 20000images with a total of 40000 images with 227 x 227 pixels with RGB channels. \n",
    "- The dataset is generated from 458 high-resolution images (4032x3024 pixel) with the method proposed by Zhang et al (2016). \n",
    "- High-resolution images have variance in terms of surface finish and illumination conditions. \n",
    "- No data augmentation in terms of random rotation or flipping is applied. \n",
    "\n",
    "Cite: Özgenel, Çağlar Fırat (2019), “Concrete Crack Images for Classification”, Mendeley Data, V2, doi: 10.17632/5y9wdsg2zt.2\n",
    "\n",
    "For more detail, you can check at this [link](https://data.mendeley.com/datasets/5y9wdsg2zt/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11fa25550>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Concrete_Dataset(Dataset):\n",
    "    def __init__(self, transform=None, train=True):\n",
    "        directory = \"./resources/data\"\n",
    "        positive = \"Positive\"\n",
    "        negative = 'Negative'\n",
    "\n",
    "        positive_file_path = os.path.join(directory, positive)\n",
    "        negative_file_path = os.path.join(directory, negative)\n",
    "        positive_files = [os.path.join(positive_file_path, file) for file in os.listdir(positive_file_path) if file.endswith(\".jpg\")]\n",
    "        negative_files = [os.path.join(negative_file_path, file) for file in os.listdir(negative_file_path) if file.endswith(\".jpg\")]\n",
    "        number_of_samples = len(positive_files) + len(negative_files)\n",
    "        self.all_files = [None] * number_of_samples\n",
    "        self.all_files[::2] = positive_files\n",
    "        self.all_files[1::2] = negative_files \n",
    "\n",
    "        self.transform = transform\n",
    "        self.Y = torch.zeros([number_of_samples]).type(torch.LongTensor)\n",
    "        self.Y[::2] = 1\n",
    "        self.Y[1::2] = 0\n",
    "        \n",
    "        if train:\n",
    "            self.all_files = self.all_files[0:30000]\n",
    "            self.Y = self.Y[0:30000]\n",
    "            self.len = len(self.all_files)\n",
    "        else:\n",
    "            self.all_files = self.all_files[30000:]\n",
    "            self.Y = self.Y[30000:]\n",
    "            self.len = len(self.all_files)     \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # image = Image.open(self.all_files[idx])\n",
    "        image = torch.load(self.all_files[idx])\n",
    "        y = self.Y[idx]\n",
    "                  \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Concrete_Dataset(train=True)\n",
    "validation_dataset = Concrete_Dataset(train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in train_dataset[0:3]:\n",
    "    plt.imshow(sample[0])\n",
    "    plt.xlabel(\"y=\"+str(sample[1].item()))\n",
    "    plt.title(\"training data, sample {}\".format(int(sample)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pretrained ResNet18\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>resnet18</code> is used to classify 1000 different objects; as a result, the last layer has 1000 outputs.  The 512 inputs come from the fact that the previously hidden layer has 512 outputs. \n",
    "\n",
    "Then, we'll replace the output layer <code>model.fc</code> of the neural network with a <code>nn.Linear</code> object, to classify 2 different classes. For the parameters <code>in_features </code> remember the last hidden layer has 512 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = 2\n",
    "\n",
    "model.fc = nn.Linear(512, number_of_classes)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# create an optimizer for the model\n",
    "optimizer = torch.optim.Adam([param for param in model.parameters() if param.requires_grad], lr=0.001)\n",
    "\n",
    "# data loader for batch processing in training and validation\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=100)\n",
    "validation_loader = DataLoader(dataset=validation_dataset, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll combine them all and start to train the model, the `loss` and `accuracy` will be recorded for further insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1\n",
    "loss_list = []\n",
    "accuracy_list = []\n",
    "N_test = len(validation_dataset)\n",
    "N_train = len(train_dataset)\n",
    "\n",
    "Loss = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for x, y in train_loader:\n",
    "        model.train() \n",
    "        # clear gradient \n",
    "        optimizer.zero_grad()\n",
    "        # make a prediction \n",
    "        z = model(x)\n",
    "        # calculate loss \n",
    "        loss = criterion(z, y)\n",
    "        # calculate gradients of parameters \n",
    "        loss.backward()\n",
    "        # update parameters \n",
    "        optimizer.step()\n",
    "        loss_list.append(loss.data)\n",
    "\n",
    "    correct = 0\n",
    "    for x_test, y_test in validation_loader:\n",
    "        # set model to eval \n",
    "        model.eval()\n",
    "        # make a prediction \n",
    "        z = model(x_test)\n",
    "        # find max \n",
    "        _, yhat = torch.max(z.data, 1)\n",
    "       \n",
    "        # calculate misclassified  samples in mini-batch \n",
    "        correct += (yhat == y_test).sum().item()  \n",
    "        \n",
    "    accuracy = correct / N_test\n",
    "    accuracy_list.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Model accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll load some misclassified samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_count = 0\n",
    "validation_single_loader = DataLoader(dataset=validation_dataset, batch_size=1)\n",
    "i = 0\n",
    "\n",
    "for x_test, y_test in validation_single_loader:\n",
    "    i += 1\n",
    "    if misclassified_count == 4:\n",
    "        break\n",
    "        \n",
    "    model.eval()\n",
    "    z = model(x_test)\n",
    "    _, yhat = torch.max(z.data, 1)\n",
    "\n",
    "    misclassified = (yhat != y_test).nonzero()\n",
    "    if len(misclassified) > 0:\n",
    "        misclassified_count += 1\n",
    "        print(f'sample {i} - predicted value: {yhat} - actual value: {y_test}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
